{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Lab 2\n",
    "\n",
    "To begin with, we'll use your function to generate a Word WFST for the word \"*peppers*\", using `generate_word_wfst('peppers')`.  By viewing this as an HMM, you'll be able to sample possible paths through the model and also generate the likelihood of an observation sequence $(x_1, \\dotsc, x_T)$.\n",
    "\n",
    "We'll build on this to implement the basics of the Viterbi algorithm, which can later be used for word recognition.\n",
    "\n",
    "First, copy your code from Lab 1 into the space below.  You can use the official solutions if you like.\n",
    "If you want to extract the code-only parts of your previous notebook, on the terminal command line you can type:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to <script-name.py> <notebook-name.ipynb>\n",
    "```\n",
    "\n",
    "where <script-name.py> and <notebook-name.ipynb> indicate the path of the script file you want to write to, and the path of the notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the WFST has been constructed, we can traverse over the states and arcs.  This example from [OpenFst](http://www.openfst.org/twiki/bin/view/FST/PythonExtension) shows how you can do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in f.states():\n",
    "    \n",
    "    # iterate over all arcs leaving this state    \n",
    "    for arc in f.arcs(state):\n",
    "         print state, arc.ilabel, arc.olabel, arc.weight, arc.nextstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could begin at the start state, and traverse in a depth-first manner.  **Warning**: the code below specifically handles self-loops, but won't work if your WFST has larger cycles in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_arcs(state):\n",
    "    \"\"\"Traverse every arc leaving a particular state\n",
    "    \"\"\"\n",
    "    for arc in f.arcs(state):\n",
    "        print state, arc.ilabel, arc.olabel, arc.weight, arc.nextstate\n",
    "        \n",
    "        if arc.next_state != state:            # don't follow the self-loops or we'll get stuck forever!\n",
    "            traverse_arcs(arc.next_state)\n",
    "\n",
    "s = f.start()\n",
    "traverse_arcs(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Write code to randomly generate (sample) a path through your word HMM for \"*peppper*\".  To sample from a list of arcs, you can use code like\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "arc_list = list(f.arcs(state))\n",
    "sampled_arc = random.sample(arc_list,1)[0]\n",
    "```\n",
    "\n",
    "  Notice that if you repeat your random sampling, you'll get paths of different lengths due to the self-loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now it's time to add probabilities to your WFST.  As mentioned at the end of Lab 1, probabilities in WFSTs are traditionally expressed in negative log format, that is, the weight $w$ on an arc transitioning between states $i$ and $j$ is given by $w=-\\log a_{ij}$, where $a_{ij}$ is the HMM transition probability.  Remember that you can add weights using the third argument to `fst.Arc()`.\n",
    "\n",
    "  Add weights to your WFSTs corresponding to transition probabilities.  Assume that the probability of a self-loop is $0.1$, and that when transitioning *between* separate phones or words, the probabilities are uniform over all transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
